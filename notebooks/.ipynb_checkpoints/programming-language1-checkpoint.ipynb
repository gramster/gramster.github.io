{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Programming Language Part 1\n",
    "\n",
    "\n",
    "date: 2019-04-30T20:10:00\n",
    "author: Graham Wheeler\n",
    "category: Programming\n",
    "comments: enabled\n",
    "draft: true\n",
    "\n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Programming Language pt 1\n",
    "\n",
    "This is the first in a series of posts about implementing programming languages. In this post I'll talk about the common basic phases of building a simple expression interpreter. I'll keep fleshing this out in further posts. My ambition is to go all the way to designing a new programming language and implementing a compiler for it. We'll see if I get there :-)\n",
    "\n",
    "I've implemented a number of compilers and virtual machines over the years and taught a graduate class in the subject several times. That was a long time ago (30 years) and I can't say I've kept up with developments but I still think this could be a fun project and an education series of posts.\n",
    "\n",
    "I'll start by using Python as the implementation language but I'd like to get to the point where I have a self-hosted language compiler: that is, my language should be rich enough and sufficiently implemented that it can have it's own compiler written in it.\n",
    "\n",
    "That will take some time. In this post I'm just going to cover the basics, with a simple expression calculator that supports variables.\n",
    "\n",
    "## The NotVeryExpressionist Language\n",
    "\n",
    "Here are some examples of the kind of programs that can be written in our simple language:\n",
    "\n",
    "    let radius = ARG1\n",
    "    let pi = 3.1415927\n",
    "    pi * radius * radius\n",
    "\n",
    "## Defining a Grammar\n",
    "\n",
    "The syntax of languages are usually defined by _formal grammars_. These were pioneered by Noah Chomsky. A _Chomsky Grammar_ or _Phrase Structure Grammar_ is a 4-tuple $(T, N, P, Z)$ where $T$ is a set of _terminal_ symbols, $N$ is a set of _non-terminal_ symbols, $P$ is a set of _productions_, and $Z$ is a start symbol. The _vocabulary_ of the grammar is the union of $N$ and $T$, and the _language_ is the set of all possible sequences of terminal symbols that can be produced from the prroductions starting from the start symbol. Put another way, the language is the (usually infinite) set of all possible syntactically correct programs defined by the grammar.\n",
    "\n",
    "For our simple language, we can use the production rules below:\n",
    "\n",
    "    program ::= statement_list\n",
    "    statement_list ::= statement | statement statement_list\n",
    "    statement ::= assignment | expression\n",
    "    assignment ::= 'let' IDENTIFIER '=' expression\n",
    "    expression ::= add_expression\n",
    "    add_expression ::= mult_expression '+' add_expression | mult_expression '-' add_expression\n",
    "    mult_expression ::= term '*' mult_expression | term '/' mult_expression\n",
    "    term ::= IDENTIFIER | NUMBER\n",
    "        \n",
    "Here, `program` is the start symbol, all the characters or character sequences in quotes are terminals, as are `IDENTIFIER` and `NUMBER`, while all the lower-case words on the left side of the production rules are non-terminals. `|` is an `or` operator and has lowest precedence. The rules above are written in a form called Backus-Naur form, or BNF (although I dropped the typical `<>` around non-terminal names).\n",
    "\n",
    "You can read this informally as:\n",
    "\n",
    "_A program is a statement list. A statement list is either a statement, or a statement followed by a statement list. A statement is either an assignment or an expression. An assignment starts with the non-terminal `let`, followed by an IDENTIFIER, an `=`, and finally an `expression`..._\n",
    "\n",
    "etc.\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "- we use the `let` keyword as the first token in an assignment distinguish an assignment from an expression. I intentionally did this to simplify our implementation. \n",
    "- we use various specializations of `expression` (`add_expression`, `mult_expression`) to reflect operator precedence.\n",
    "\n",
    "Sometimes BNF is enhanced with regular expression-like operators, so the rule for `statement_list` might be written as any of:\n",
    "\n",
    "    statement_list ::= statement [statement_list]\n",
    "    statement_list ::= statement statement_list*\n",
    "    statement_list ::= statement+\n",
    "\n",
    "Looking at the most of these variants, its clear that `statement_list` is defined recursively. In this particular case the recursion is on the right-hand end of the production rule. We could also have written:\n",
    "\n",
    "    statement_list ::= [statement_list] statement\n",
    "\n",
    "The first is what we call \"right-recursive\" as it refers to itself recursively with the rightmost element, while the second is \"left recursive\". \n",
    "You will see later that depending on how we implement our language parser, this difference can be important and we sometimes have to rewrite our grammar in a different recursive form to be able to implement it.\n",
    "Some languages can only be easily expressed using one of these forms; they're not always easily interchangeable like here. For us, we will use a \"recursive descent\" parser, which reflects the grammar rules. In such a parser we always want to make some forward progress in the program before we recurse, so we avoid left-recursion where we could recurse infinitely with no progress.\n",
    "\n",
    "In general, whitespace is not considered significant; this is true in many languages (although not in Python). We usually assume that symbols in the grammar can be separated by arbitrary amounts of whitespace.\n",
    "\n",
    "You'll notice we never defined `IDENTIFIER` or `NUMBER`. These are terminals, but we can still define them with production rules. The difference now is that whitespace is not allowed unless it is explicitly defined:\n",
    "\n",
    "    IDENTIFIER ::= LETTER_OR_UNDERSCORE LETTER_OR_UNDERSCORE_OR_DIGIT*.\n",
    "    NUMBER ::= ['-'] DIGIT+ [ '.' DIGIT*.\n",
    "    LETTER_OR_UNDERSCORE ::= LETTER | '_'.\n",
    "    LETTER_OR_UNDERSCORE_OR_DIGIT ::= LETTER | DIGIT | '_'.\n",
    "    LETTER ::= 'A' | ... | 'Z' | 'a' | ... | 'z'.\n",
    "    DIGIT ::= '0' | ... | '9'.\n",
    "\n",
    "The terminal symbols that are character sequences in most languages can't be used as identifiers; these are called \"reserved words\". In our language the only reserved word is `let`.\n",
    "\n",
    "We'll use `ARGn` as a special set of identifiers for the command line arguments.\n",
    "\n",
    "## Tokenizing a Program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_token(expect=None):\n",
    "    global token, pos, line, col\n",
    "    if expect and token != expect:\n",
    "        raise Exception(f\"Expected {expect} at {line}:{col}\")\n",
    "    # skip whitespace\n",
    "    while pos < len(text) and text[pos].isspace():\n",
    "        if text[pos] == '\\n':\n",
    "            col = 0\n",
    "            line += 1\n",
    "        else:\n",
    "            col += 1\n",
    "        pos += 1\n",
    "        \n",
    "    if pos == len(text):\n",
    "        token = None\n",
    "        return\n",
    "    \n",
    "    startpos = pos\n",
    "    \n",
    "    if text[pos].isdigit():\n",
    "        while pos < len(text) and (text[pos].isdigit() or text[pos] == '.'):\n",
    "            pos += 1\n",
    "    elif text[pos].isalpha():\n",
    "        while pos < len(text) and text[pos].isalnum():\n",
    "            pos += 1\n",
    "    else:\n",
    "        pos += 1\n",
    "            \n",
    "    token = text[startpos:pos]\n",
    "    col += pos - startpos\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:7 let\n",
      "2:14 radius\n",
      "2:16 =\n",
      "2:21 ARG1\n",
      "3:7 let\n",
      "3:10 pi\n",
      "3:12 =\n",
      "3:22 3.1415927\n",
      "4:6 pi\n",
      "4:8 *\n",
      "4:15 radius\n",
      "4:17 *\n",
      "4:24 radius\n",
      "5:0 None\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "    let radius = ARG1\n",
    "    let pi = 3.1415927\n",
    "    pi * radius * radius\n",
    "\"\"\"\n",
    "\n",
    "pos = 0\n",
    "line = 1\n",
    "col = 0\n",
    "\n",
    "while True:\n",
    "    next_token()\n",
    "    print(f\"{line}:{col} {token}\")\n",
    "    if not token:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number():\n",
    "    next_token()\n",
    "\n",
    "def identifier():\n",
    "    next_token()\n",
    "    \n",
    "def term():\n",
    "    if not token:\n",
    "        raise Exception(f\"Premature end of program at {line}:{col}!\")\n",
    "    elif token[0] == '-':\n",
    "        next_token()\n",
    "        number()\n",
    "    elif token[0].isdigit():\n",
    "        number()\n",
    "    else:\n",
    "        identifier()\n",
    "    \n",
    "def assignment():\n",
    "    next_token('let')\n",
    "    identifier()\n",
    "    next_token('=')\n",
    "    expression()\n",
    "    \n",
    "def mult_expression():\n",
    "    term()\n",
    "    if token == '*' or token == '/':\n",
    "        next_token()\n",
    "        mult_expression()\n",
    "   \n",
    "def add_expression():\n",
    "    mult_expression()\n",
    "    if token == '+' or token == '-':\n",
    "        next_token()\n",
    "        add_expression()\n",
    "        \n",
    "def expression():\n",
    "    add_expression()\n",
    "    \n",
    "def statement():\n",
    "    if token == 'let':\n",
    "        assignment()\n",
    "    else:\n",
    "        expression()\n",
    "    \n",
    "def statement_list():\n",
    "    statement()\n",
    "    if token:\n",
    "        statement_list()\n",
    "\n",
    "def program(body):\n",
    "    global pos, text, token, line, col\n",
    "    text = body\n",
    "    line = 1\n",
    "    pos = 0\n",
    "    col = 0\n",
    "    token = None\n",
    "    next_token()\n",
    "    statement_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\"\"\n",
    "    let radius = ARG1\n",
    "    let pi = 3.1415927\n",
    "    pi * radius * radius\n",
    "\"\"\"\n",
    "\n",
    "program(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number():\n",
    "    value = float(token)\n",
    "    next_token()\n",
    "    return value\n",
    "    \n",
    "def identifier():\n",
    "    if token in context:\n",
    "        value = context[token]\n",
    "    else:\n",
    "        raise Exception(f\"Undefined variable {token} at {line}:{col}\")\n",
    "    next_token()\n",
    "    return value\n",
    "\n",
    "def term():\n",
    "    if not token:\n",
    "        raise Exception(f\"Premature end of file at {line}:{col}!\")\n",
    "    elif token[0] == '-':\n",
    "        next_token()\n",
    "        value = -number()\n",
    "    elif token[0].isdigit():\n",
    "        value = number()\n",
    "    else:\n",
    "        value = identifier()\n",
    "    return value\n",
    "    \n",
    "def assignment():\n",
    "    global context\n",
    "    next_token('let')\n",
    "    varname = token\n",
    "    next_token()\n",
    "    # Note - we don't use identifier() as LHS and RHS have different meaning.\n",
    "    next_token('=')\n",
    "    value = expression()\n",
    "    context[varname] = value\n",
    "    return value\n",
    "    \n",
    "def mult_expression():\n",
    "    value = term()\n",
    "    if token == '*':\n",
    "        next_token()\n",
    "        value *= mult_expression()\n",
    "    elif token == '/':\n",
    "        next_token()\n",
    "        value /= mult_expression()\n",
    "    return value\n",
    "            \n",
    "def expression():\n",
    "    value = mult_expression()\n",
    "    if token == '+':\n",
    "        next_token()\n",
    "        value += expression()\n",
    "    elif token == '-':\n",
    "        next_token()\n",
    "        value -= expression()\n",
    "    return value\n",
    "    \n",
    "def statement():\n",
    "    if token == 'let':\n",
    "        value = assignment()\n",
    "    else:\n",
    "        value = expression()\n",
    "    return value\n",
    "    \n",
    "def statement_list():\n",
    "    value = statement()\n",
    "    if token:\n",
    "        value = statement_list()\n",
    "    return value\n",
    "\n",
    "def program(body, arguments=None):\n",
    "    global pos, text, token, line, col, context\n",
    "    text = body\n",
    "    line = 1\n",
    "    pos = 0\n",
    "    col = 0\n",
    "    token = None\n",
    "    context = {}\n",
    "    if arguments:\n",
    "        context = {f'ARG{i+1}': v for i, v in enumerate(arguments)}\n",
    "    nexttoken()\n",
    "    value = statement_list()\n",
    "    print(f\"Last value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last value: 78.5398175\n"
     ]
    }
   ],
   "source": [
    "program(p, arguments=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
